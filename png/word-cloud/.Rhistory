}
# Loop through each url and see if exists
urls
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
library(tidyverse)
library(RSelenium)
# Start a Selenium server and client; set Chrome as the client port
rD <- rsDriver(verbose = FALSE, port = 4444L, browser = "chrome")
chrome <- rD$client
# Get Wikipedia's list of hip hop musicians
chrome$navigate("https://en.wikipedia.org/wiki/List_of_hip_hop_musicians")
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should be removed
name <- gsub("\\.", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should be removed
artist_names[i] <- gsub("\\.", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
foo <- "Rappin'-4-Tay"
print(gsub("\', "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\'", "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\"", "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\"", "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\'", "", foo))
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should also be removed
artist_names[i] <- gsub("\\.", "", artist_names[i])
# Remove single quotes
artist_names[i] <- gsub("\'", "", artist_names[i])
# Remove double quotes
#artist_names[i] <- gsub("\"", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
artist_names
foo <- "Royce Da 5'9\""
print(gsub("\"", "", foo))
foo <- "Royce Da 5'9\""
foo <- "Royce Da 5'9\""
foo
print(gsub("\"", "", foo))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should also be removed
artist_names[i] <- gsub("\\.", "", artist_names[i])
# Remove single quotes
artist_names[i] <- gsub("\'", "", artist_names[i])
# Remove double quotes
#artist_names[i] <- gsub("\"", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
artist_names
artist_names[1000:1100]
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format artist names for URLs
for (i in 1:length(artist_names)) {
# Remove escaped double quotes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove single quotes
artist_names[i] <- gsub("\'", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Remove periods
artist_names[i] <- gsub("\\.", "", artist_names[i])
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
urls
urls[1000:1100]
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format artist names for URLs
for (i in 1:length(artist_names)) {
# Remove escaped double quotes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
artist_names[i] <- gsub("\\.", "", artist_names[i])
artist_names[i] <- gsub("\'", "", artist_names[i])
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
urls
library(tidyverse)
library(RSelenium)
# Start a Selenium server and client; set Chrome as the client port
rD <- rsDriver(verbose = FALSE, port = 4444L, browser = "chrome")
chrome <- rD$client
chrome$navigate("https://genius.com/artists/kendrick-lamar")
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
webElems
print(webElems)
chrome$navigate("https://genius.com/artists/kendrick-lamar")
webElems <- chrome$findElements(using = "class name", value = "full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "xpath", value = "full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "xpath", value = "//*full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "class name", value = "full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "class name", value = "full_width_button")
webElems
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]/svg/path")
webElems
source('~/Programming/r/rap-analyses/functions.R', echo=TRUE)
chrome$navigate("https://genius.com/artists/kendrick-lamar")
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]")
webElems
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/modal-window")
webElems
print(webElems)
print(unlist(lapply(webElems, function(x){x$getElementText()})))
print(unlist(lapply(webElems, function(x){x$getElementText()})))
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]")
print(unlist(lapply(webElems, function(x){x$getElementText()})))
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]/svg/path")
print(unlist(lapply(webElems, function(x){x$getElementText()})))
# install.packages("data.table")
# install.packages("tidytext")
# install.packages("wordcloud")
library(data.table)
library(tidytext)
library(tidyverse)
library(dplyr)
library(stringr)
library(wordcloud)
# Location of rap data
dataDir = "/Users/zacharysnoek/Programming/r/rap-analyses/csv"
dataSet = "dataset_1.csv"
# Location of plots script
plotsScript = "/Users/zacharysnoek/Programming/r/rap-analyses/plots.R"
# Output directory of plots
baseDir = "/Users/zacharysnoek/Programming/r/rap-analyses/png/"
wordCountDir = paste(baseDir, "word-count", sep="")
netSentimentDir = paste(baseDir, "net-sentiment", sep="")
mostCommonPosNegWordsDir = paste(baseDir, "most-common-pos-neg-words", sep="")
wordCloudDir = paste(baseDir, "word-cloud", sep="")
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
#for (i in 1:length(artists)) {
# Get the lyrics for each rapper
rapper <- toString(artists[1])
filtered_df <- filter(initial, artist == rapper)
text <- filtered_df %>%
pull(lyrics)
# Tokenize lyrics
lyrics_df <- as_tibble(text) %>%
unnest_tokens(word, value)
# Remove stop words
data("stop_words")
lyrics_df <- lyrics_df %>%
anti_join(stop_words)
#======= WORD CLOUD =======#
setwd(wordCloudDir)
wordCloud(lyrics_df, rapper)
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
#for (i in 1:length(artists)) {
# Get the lyrics for each rapper
rapper <- toString(artists[1])
filtered_df <- filter(initial, artist == rapper)
text <- filtered_df %>%
pull(lyrics)
# Tokenize lyrics
lyrics_df <- as_tibble(text) %>%
unnest_tokens(word, value)
# Remove stop words
data("stop_words")
lyrics_df <- lyrics_df %>%
anti_join(stop_words)
#======= WORD CLOUD =======#
setwd(wordCloudDir)
wordCloud(lyrics_df, rapper)
# Location of rap data
dataDir = "/Users/zacharysnoek/Programming/r/rap-analyses/csv"
dataSet = "dataset_1.csv"
# Location of plots script
plotsScript = "/Users/zacharysnoek/Programming/r/rap-analyses/plots.R"
# Output directory of plots
baseDir = "/Users/zacharysnoek/Programming/r/rap-analyses/png/"
wordCountDir = paste(baseDir, "word-count", sep="")
netSentimentDir = paste(baseDir, "net-sentiment", sep="")
mostCommonPosNegWordsDir = paste(baseDir, "most-common-pos-neg-words", sep="")
wordCloudDir = paste(baseDir, "word-cloud", sep="")
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
#for (i in 1:length(artists)) {
# Get the lyrics for each rapper
rapper <- toString(artists[1])
filtered_df <- filter(initial, artist == rapper)
text <- filtered_df %>%
pull(lyrics)
# Tokenize lyrics
lyrics_df <- as_tibble(text) %>%
unnest_tokens(word, value)
# Remove stop words
data("stop_words")
lyrics_df <- lyrics_df %>%
anti_join(stop_words)
#======= WORD CLOUD =======#
setwd(wordCloudDir)
wordCloud(lyrics_df, rapper)
# install.packages("data.table")
# install.packages("tidytext")
# install.packages("wordcloud")
library(data.table)
library(tidytext)
library(tidyverse)
library(dplyr)
library(stringr)
library(wordcloud)
# Location of rap data
dataDir = "/Users/zacharysnoek/Programming/r/rap-analyses/csv"
dataSet = "dataset_1.csv"
# Location of plots script
plotsScript = "/Users/zacharysnoek/Programming/r/rap-analyses/plots.R"
# Output directory of plots
baseDir = "/Users/zacharysnoek/Programming/r/rap-analyses/png/"
wordCountDir = paste(baseDir, "word-count", sep="")
netSentimentDir = paste(baseDir, "net-sentiment", sep="")
mostCommonPosNegWordsDir = paste(baseDir, "most-common-pos-neg-words", sep="")
wordCloudDir = paste(baseDir, "word-cloud", sep="")
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
#for (i in 1:length(artists)) {
# Get the lyrics for each rapper
rapper <- toString(artists[1])
filtered_df <- filter(initial, artist == rapper)
text <- filtered_df %>%
pull(lyrics)
# Tokenize lyrics
lyrics_df <- as_tibble(text) %>%
unnest_tokens(word, value)
# Remove stop words
data("stop_words")
lyrics_df <- lyrics_df %>%
anti_join(stop_words)
#======= WORD CLOUD =======#
setwd(wordCloudDir)
wordCloud(lyrics_df, rapper)
# install.packages("data.table")
# install.packages("tidytext")
# install.packages("wordcloud")
library(data.table)
library(tidytext)
library(tidyverse)
library(dplyr)
library(stringr)
library(wordcloud)
# Location of rap data
dataDir = "/Users/zacharysnoek/Programming/r/rap-analyses/csv"
dataSet = "dataset_1.csv"
# Location of plots script
plotsScript = "/Users/zacharysnoek/Programming/r/rap-analyses/plots.R"
# Output directory of plots
baseDir = "/Users/zacharysnoek/Programming/r/rap-analyses/png/"
wordCountDir = paste(baseDir, "word-count", sep="")
netSentimentDir = paste(baseDir, "net-sentiment", sep="")
mostCommonPosNegWordsDir = paste(baseDir, "most-common-pos-neg-words", sep="")
wordCloudDir = paste(baseDir, "word-cloud", sep="")
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
#for (i in 1:length(artists)) {
# Get the lyrics for each rapper
rapper <- toString(artists[1])
filtered_df <- filter(initial, artist == rapper)
text <- filtered_df %>%
pull(lyrics)
# Tokenize lyrics
lyrics_df <- as_tibble(text) %>%
unnest_tokens(word, value)
# Remove stop words
data("stop_words")
lyrics_df <- lyrics_df %>%
anti_join(stop_words)
#======= WORD CLOUD =======#
setwd(wordCloudDir)
wordCloud(lyrics_df, rapper)
#}
#}
# install.packages("data.table")
# install.packages("tidytext")
# install.packages("wordcloud")
library(data.table)
library(tidytext)
library(tidyverse)
library(dplyr)
library(stringr)
library(wordcloud)
# Location of rap data
dataDir = "/Users/zacharysnoek/Programming/r/rap-analyses/csv"
dataSet = "dataset_1.csv"
# Location of plots script
plotsScript = "/Users/zacharysnoek/Programming/r/rap-analyses/plots.R"
# Output directory of plots
baseDir = "/Users/zacharysnoek/Programming/r/rap-analyses/png/"
wordCountDir = paste(baseDir, "word-count", sep="")
netSentimentDir = paste(baseDir, "net-sentiment", sep="")
mostCommonPosNegWordsDir = paste(baseDir, "most-common-pos-neg-words", sep="")
wordCloudDir = paste(baseDir, "word-cloud", sep="")
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
#for (i in 1:length(artists)) {
# Get the lyrics for each rapper
rapper <- toString(artists[1])
filtered_df <- filter(initial, artist == rapper)
text <- filtered_df %>%
pull(lyrics)
# Tokenize lyrics
lyrics_df <- as_tibble(text) %>%
unnest_tokens(word, value)
# Remove stop words
data("stop_words")
lyrics_df <- lyrics_df %>%
anti_join(stop_words)
#======= WORD CLOUD =======#
setwd(wordCloudDir)
wordCloud(lyrics_df, rapper)
# install.packages("data.table")
# install.packages("tidytext")
# install.packages("wordcloud")
library(data.table)
library(tidytext)
library(tidyverse)
library(dplyr)
library(stringr)
library(wordcloud)
# Location of rap data
dataDir = "/Users/zacharysnoek/Programming/r/rap-analyses/csv"
dataSet = "dataset_1.csv"
# Location of plots script
plotsScript = "/Users/zacharysnoek/Programming/r/rap-analyses/plots.R"
# Output directory of plots
baseDir = "/Users/zacharysnoek/Programming/r/rap-analyses/png/"
wordCountDir = paste(baseDir, "word-count", sep="")
netSentimentDir = paste(baseDir, "net-sentiment", sep="")
mostCommonPosNegWordsDir = paste(baseDir, "most-common-pos-neg-words", sep="")
wordCloudDir = paste(baseDir, "word-cloud", sep="")
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
#for (i in 1:length(artists)) {
# Get the lyrics for each rapper
rapper <- toString(artists[1])
filtered_df <- filter(initial, artist == rapper)
text <- filtered_df %>%
pull(lyrics)
# Tokenize lyrics
lyrics_df <- as_tibble(text) %>%
unnest_tokens(word, value)
# Remove stop words
data("stop_words")
lyrics_df <- lyrics_df %>%
anti_join(stop_words)
#======= WORD CLOUD =======#
setwd(wordCloudDir)
wordCloud(lyrics_df, rapper)
