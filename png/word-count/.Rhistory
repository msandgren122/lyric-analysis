grep("\\(|\\)", artist_names)
# Remove artists with parentheticals in heading
parentheticals <- grep("\\(|\\)", artist_names)
# Remove artists with parentheticals in heading
parentheticals <- grep("\\(|\\)", artist_names)
parentheticals
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names <- artist_names[-paren]
print(artist_names)
print(artist_names)
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
print(artist_names)
print(artist_names)
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
print(artist_names)
print(artist_names)
backup <- artist_names
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
print(artist_names)
# Remove last 3 entries
paren
# Remove last 3 entries
tail(artist_names)
# Remove last 3 entries (Wiki headings)
tail(artist_names)
artist_names <- x[1:(length(artist_names)-3)]
artist_names <- artist_names[1:(length(artist_names)-3)]
tail(artist_names)
# important to always run these to close out the browser and server
# forgetting to stop the server will give you a 'port already in use'
# error the next time you try to start a browser
chrome$close()
rD$server$stop()
library(tidyverse)
library(RSelenium)
# start a selnium server and client
# set chrome as the client part. chrome is what we'll use to navigate around
rD <- rsDriver(verbose = FALSE, port = 4444L, browser = "chrome")
chrome <- rD$client
# go to a URL this way
chrome$navigate("http://www.google.com")
chrome$navigate("http://genius.com/verified-artists")
#gets artist page URLs
# well, it worked yesterday but it broke
# unlist(lapply(webElems, function(x){x$getElementAttribute('href')}))
#get wikipedias list of hiphop musicians
chrome$navigate("https://en.wikipedia.org/wiki/List_of_hip_hop_musicians")
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
# important to always run these to close out the browser and server
# forgetting to stop the server will give you a 'port already in use'
# error the next time you try to start a browser
chrome$close()
rD$server$stop()
library(tidyverse)
library(RSelenium)
# start a selnium server and client
# set chrome as the client part. chrome is what we'll use to navigate around
rD <- rsDriver(verbose = FALSE, port = 4444L, browser = "chrome")
chrome <- rD$client
#gets artist page URLs
# well, it worked yesterday but it broke
# unlist(lapply(webElems, function(x){x$getElementAttribute('href')}))
#get wikipedias list of hiphop musicians
chrome$navigate("https://en.wikipedia.org/wiki/List_of_hip_hop_musicians")
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
print(artist_names)
backup <- artist_names
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
artist_names
# important to always run these to close out the browser and server
# forgetting to stop the server will give you a 'port already in use'
# error the next time you try to start a browser
chrome$close()
rD$server$stop()
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
name <- "Kendrick Lamar"
sprintf(artist_page, name)
name <- "Kendrick Lamar"
sprintf("%s%s", artist_page, name)
name <- "Kendrick Lamar"
name <- gsub(" ", "-", name)
sprintf("%s%s", artist_page, name)
name <- "Kendrick Lamar is cool"
name <- gsub(" ", "-", name)
sprintf("%s%s", artist_page, name)
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- sprintf("%s%s", artist_page, artist_names[i])
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name
name <- sprintf("%s%s", artist_page, artist_names[i])
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name)
#name <- sprintf("%s%s", artist_page, artist_names[i])
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
#name <- paste(artist_page, name)
name <- sprintf("%s%s", artist_page, artist_names[i])
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
# Always run these to close out the browser and server.
# Forgetting to stop the server will give you a 'port already in use'
# error the next time you try to start a browser
chrome$close()
# Loop through each url and see if exists
urls
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
#name <- paste(artist_page, name)
name <- sprintf("%s%s", artist_page, artist_names[i])
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
#name <- paste(artist_page, name)
name <- sprintf("%s%s", artist_page, name)
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
#name <- paste(artist_page, name)
name <- sprintf("%s%s", artist_page, name)
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
#name <- sprintf("%s%s", artist_page, name)
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
#name <- sprintf("%s%s", artist_page, name)
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
name <- gsub("\.", "", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
name <- gsub("\\.", "", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
#name <- gsub("\\.", "", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
#name <- gsub("\\.", "", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
name <- gsub("\\.", "", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
# Always run these to close out the browser and server.
# Forgetting to stop the server will give you a 'port already in use'
# error the next time you try to start a browser
chrome$close()
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
name <- gsub("\\.", "", name)
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
library(tidyverse)
library(RSelenium)
# Start a Selenium server and client; set Chrome as the client port
rD <- rsDriver(verbose = FALSE, port = 4444L, browser = "chrome")
chrome <- rD$client
# Get Wikipedia's list of hip hop musicians
chrome$navigate("https://en.wikipedia.org/wiki/List_of_hip_hop_musicians")
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should be removed
name <- gsub("\\.", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should be removed
artist_names[i] <- gsub("\\.", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
# Loop through each url and see if exists
urls
foo <- "Rappin'-4-Tay"
print(gsub("\', "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\'", "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\"", "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\"", "", foo))
foo <- "Rappin'-4-Tay"
print(gsub("\'", "", foo))
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should also be removed
artist_names[i] <- gsub("\\.", "", artist_names[i])
# Remove single quotes
artist_names[i] <- gsub("\'", "", artist_names[i])
# Remove double quotes
#artist_names[i] <- gsub("\"", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
artist_names
foo <- "Royce Da 5'9\""
print(gsub("\"", "", foo))
foo <- "Royce Da 5'9\""
foo <- "Royce Da 5'9\""
foo
print(gsub("\"", "", foo))
# Format strings
for (i in 1:length(artist_names)) {
# Remove escape character backslashes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Guessing that periods should also be removed
artist_names[i] <- gsub("\\.", "", artist_names[i])
# Remove single quotes
artist_names[i] <- gsub("\'", "", artist_names[i])
# Remove double quotes
#artist_names[i] <- gsub("\"", "", artist_names[i])
# Will also need to clean up other stuff in the URLs once we figure out
# what isn't included
}
artist_names
artist_names[1000:1100]
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format artist names for URLs
for (i in 1:length(artist_names)) {
# Remove escaped double quotes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove single quotes
artist_names[i] <- gsub("\'", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
# Remove periods
artist_names[i] <- gsub("\\.", "", artist_names[i])
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
urls
urls[1000:1100]
artist_names <- unlist(lapply(webElems, function(x){x$getElementText()}))
# Format artist names for URLs
for (i in 1:length(artist_names)) {
# Remove escaped double quotes
artist_names[i] <- gsub("\"", "", artist_names[i])
# Remove Wiki reference numbers
artist_names[i] <- gsub("\\[\\d\\]", "", artist_names[i])
artist_names[i] <- gsub("\\.", "", artist_names[i])
artist_names[i] <- gsub("\'", "", artist_names[i])
}
# Remove artists with parentheticals in heading
paren <- grep("\\(|\\)", artist_names)
artist_names = artist_names[-paren]
# Remove last 3 entries (Wiki headings)
artist_names <- artist_names[1:(length(artist_names)-3)]
# Construct genius.com artist page urls
artist_page <- "https://genius.com/artists/" # Every Genius artist page is found in /artists
urls = c()
for (i in 1:length(artist_names)) {
# Probably not the right way to do this in R
name <- gsub(" ", "-", artist_names[i])
name <- paste(artist_page, name, sep = "")
urls <- c(urls, name)
}
urls
library(tidyverse)
library(RSelenium)
# Start a Selenium server and client; set Chrome as the client port
rD <- rsDriver(verbose = FALSE, port = 4444L, browser = "chrome")
chrome <- rD$client
chrome$navigate("https://genius.com/artists/kendrick-lamar")
webElems <- chrome$findElements(using = "xpath", value = "//*[@id='mw-content-text']/div/div/ul/li")
webElems
print(webElems)
chrome$navigate("https://genius.com/artists/kendrick-lamar")
webElems <- chrome$findElements(using = "class name", value = "full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "xpath", value = "full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "xpath", value = "//*full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "class name", value = "full_width_button u-clickable u-quarter_top_margin")
webElems <- chrome$findElements(using = "class name", value = "full_width_button")
webElems
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]/svg/path")
webElems
source('~/Programming/r/rap-analyses/functions.R', echo=TRUE)
chrome$navigate("https://genius.com/artists/kendrick-lamar")
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]")
webElems
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/modal-window")
webElems
print(webElems)
print(unlist(lapply(webElems, function(x){x$getElementText()})))
print(unlist(lapply(webElems, function(x){x$getElementText()})))
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]")
print(unlist(lapply(webElems, function(x){x$getElementText()})))
webElems <- chrome$findElements(using = "xpath", value = "/html/body/routable-page/ng-outlet/routable-profile-page/ng-outlet/routed-page/profile-page/div[3]/div[2]/artist-songs-and-albums/album-grid/div[2]/svg/path")
print(unlist(lapply(webElems, function(x){x$getElementText()})))
library(data.table)
library(tidytext)
library(tidyverse)
library(dplyr)
# Location of rap data
dataDir = "/Users/zacharysnoek/Programming/r/rap-data"
dataSet = "dataset_1.csv"
# Location of plots script
plotsScript = "/Users/zacharysnoek/Programming/r/rap-analyses/plots.R"
# Output directory of plots
output = "/Users/zacharysnoek/Programming/r/rap-analyses/png/word-count"
source(plotsScript)
setwd(dataDir)
# Load dataset
initial <- fread(dataSet, sep2 = "|")
initial[, collaborators := NULL]
# String cleaning
initial <- initial %>%
mutate(lyrics = gsub("\\[.*?\\]", "", lyrics)) %>%
mutate(lyrics = gsub("\\(.*?\\)", "", lyrics)) %>%
mutate(lyrics = gsub("\\\\", "", lyrics))
# Create a list of unique artsts
artists <- initial$artist %>% unique()
# Use a small subset to test with
#artists <- artists[1:10]
simple_wordCount(artists, 50, output)
